# GPU Worker Node Docker Compose
# This runs on GPU machines, connecting to management node at 10.10.100.88
# Includes: Alloy (local) and 8 GPU nodes

services:
  # Alloy observability service (local to this worker)
  alloy:
    build:
      context: .
      dockerfile: Dockerfile.alloy
    volumes:
      - ./config.alloy:/etc/alloy/test.alloy
    ports:
      - "12345:12345"
      - "4317:4317"
      - "4318:4318"
    command: ["run", "--server.http.listen-addr=0.0.0.0:12345", "--storage.path=/var/lib/alloy/data", "/etc/alloy/test.alloy"]

  # Redis service (exposed for GPU workers)
  redis:
    image: bitnamisecure/redis:latest
    environment:
      - REDIS_PASSWORD=redispassword
      - REDIS_AOF_ENABLED=no
      - REDIS_MAXMEMORY=25gb
      - REDIS_MAXMEMORY_POLICY=volatile-lru
    volumes:
      - redis_data:/bitnami/redis/data
    ports:
      - "0.0.0.0:6379:6379"
    deploy:
      resources:
        limits:
          memory: 100G
        reservations:
          memory: 100G

  # GPU Node 0

  # 0, 1, 3
  # NODE_REDIS_NODES=redis://:redispassword@10.10.100.29:6379/0,redis://:redispassword@10.10.100.98:6379/0,redis://:redispassword@10.10.100.88:6379/0
  # 0, 1, 2
  # NODE_REDIS_NODES=redis://:redispassword@10.10.100.29:6379/0,redis://:redispassword@10.10.100.98:6379/0,redis://:redispassword@10.10.100.99:6379/0
  gpu0:
    image: ghcr.io/succinctlabs/sp1-cluster-wip:node-gpu-db1c2f7
    environment:
      - NODE_COORDINATOR_RPC=http://10.10.100.88:50053
      - WORKER_MAX_WEIGHT_OVERRIDE=24
      - NODE_ARTIFACT_STORE=redis
      - NODE_REDIS_NODES=redis://:redispassword@10.10.100.88:6379/0
      - WORKER_TYPE=GPU
      - RUST_LOG=debug,tower=info,h2=info,tonic-web=info,hyper-util=info
      - TRACING_ENABLED=true
      - OTLP_ENDPOINT=http://alloy:4317
      - NO_COLOR=true
      # - SP1_WORKER_USE_FIXED_PK=true
      # - SP1_WORKER_VERIFY_INTERMEDIATES=false
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 80G
        reservations:
          memory: 80G
    cpuset: "0-63"  # First half of NUMA node 0
    depends_on:
      - alloy
    runtime: nvidia

  gpu1:
    environment:
      - CUDA_VISIBLE_DEVICES=1
    cpuset: "64-127"  # Second half of NUMA node 0
    extends:
      service: gpu0

  gpu2:
    environment:
      - CUDA_VISIBLE_DEVICES=2
    cpuset: "128-191"  # First half of NUMA node 1
    extends:
      service: gpu0

  gpu3:
    environment:
      - CUDA_VISIBLE_DEVICES=3
    cpuset: "192-255"  # Second half of NUMA node 1
    extends:
      service: gpu0

  gpu4:
    environment:
      - CUDA_VISIBLE_DEVICES=4
    cpuset: "256-319"  # First half of NUMA node 2
    extends:
      service: gpu0

  gpu5:
    environment:
      - CUDA_VISIBLE_DEVICES=5
    cpuset: "320-383"  # Second half of NUMA node 2
    extends:
      service: gpu0

  gpu6:
    environment:
      - CUDA_VISIBLE_DEVICES=6
    cpuset: "384-447"  # First half of NUMA node 3
    extends:
      service: gpu0

  gpu7:
    environment:
      - CUDA_VISIBLE_DEVICES=7
    cpuset: "448-511"  # Second half of NUMA node 3
    extends:
      service: gpu0

volumes:
  redis_data:
